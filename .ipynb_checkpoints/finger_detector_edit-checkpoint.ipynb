{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "class HandDetector():\n",
    "    def __init__(self, mode = False, max_hands = 2, det_rel_value = 1, tra_rel_value = 0.5):\n",
    "        '''\n",
    "        Initialization\n",
    "        Arguments:\n",
    "            mode: determine if receives static picture, default to be False\n",
    "            max_hands: maximum number of hands which can be detected, default to be 2\n",
    "            det_rel_value: minimum detection reliability value，default to be 1\n",
    "            tra_rel_value: minimum tracking reliability value，default to be 0.5\n",
    "        '''\n",
    "        self.mode = mode\n",
    "        self.max_hands = max_hands\n",
    "        self.det_rel_value = det_rel_value\n",
    "        self.tra_rel_value = tra_rel_value\n",
    "        self.hands = mp.solutions.hands.Hands(self.mode, self.max_hands, self.det_rel_value, self.tra_rel_value)\n",
    "\n",
    "    def find_hands(self, image, is_diagram = True):\n",
    "        '''\n",
    "        Hand detection\n",
    "        Arguments:\n",
    "            image: video frame picture\n",
    "            is_diagram: if correctly draw the diagram of hands\n",
    "        Return: \n",
    "            image: processed video frame picture\n",
    "        '''\n",
    "        imgRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Process the picture, detect whether gesture detected, save the data in self.results\n",
    "        self.results = self.hands.process(imgRGB)\n",
    "        if is_diagram:\n",
    "            if self.results.multi_hand_landmarks:\n",
    "                for hand_pos in self.results.multi_hand_landmarks:\n",
    "                    mp.solutions.drawing_utils.draw_landmarks(image, hand_pos, mp.solutions.hands.HAND_CONNECTIONS)\n",
    "        return image\n",
    "\n",
    "    def find_positions(self, image, serial_num_hand = 0):\n",
    "        '''\n",
    "        Get gesture information\n",
    "        Arguments:\n",
    "            image: Video frame picture\n",
    "            serial_num_hand: Hand's serial number, default to be 1\n",
    "        Return:\n",
    "            hand_list:\n",
    "            Gesture information list, which is composed of ind(hand's serial number),\n",
    "            pos_x(x_axis position on the screen), pos_y(y_axis position on the screen)\n",
    "        '''\n",
    "        self.hand_list = []\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            hand = self.results.multi_hand_landmarks[serial_num_hand]\n",
    "            for ind, pos in enumerate(hand.landmark):\n",
    "                height, width, length = image.shape\n",
    "                pos_x, pos_y = int(pos.x * width), int(pos.y * height)\n",
    "                self.hand_list.append([ind, pos_x, pos_y])\n",
    "        return self.hand_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# six pictures of hands, representing number 0-5\n",
    "target_pic_list = [\n",
    "    'source/0.png',\n",
    "    'source/1.png',\n",
    "    'source/2.png',\n",
    "    'source/3.png',\n",
    "    'source/4.png',\n",
    "    'source/5.png'\n",
    "]\n",
    "image_list = []\n",
    "\n",
    "for ind in target_pic_list:\n",
    "    finger_ind = cv2.imread(ind)\n",
    "    image_list.append(finger_ind)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "# Create a gesture recognition object\n",
    "detector = HandDetector()\n",
    "\n",
    "\n",
    "# Fingertip list\n",
    "# representing the fingertips of thumb, index finger, middle finger, ring finger and little finger in order\n",
    "fingertip_ind = [4, 8, 12, 16, 20]\n",
    "\n",
    "while True:\n",
    "    is_detected, image = capture.read()\n",
    "\n",
    "    if is_detected:\n",
    "        # Detect gesture\n",
    "        image = detector.find_hands(image, is_diagram = True)\n",
    "        # Get gesture information\n",
    "        finger_inf_list = detector.find_positions(image)\n",
    "        if len(finger_inf_list) > 0:\n",
    "            fingers = []\n",
    "            for ind in fingertip_ind:\n",
    "                # Find the position of each fingertip\n",
    "                x, y = finger_inf_list[ind][1], finger_inf_list[ind][2]\n",
    "                cv2.circle(image, (x, y), 10, (0, 255, 0), cv2.FILLED)\n",
    "                # If thumb detected, \n",
    "                # check if the x position of the fingertip is greater than the x position of the second joint, \n",
    "                # if true, the thumb is considered to be open, \n",
    "                # otherwise, the thumb is considered to be closed.\n",
    "                if ind == 4:\n",
    "                    if finger_inf_list[ind][1] > finger_inf_list[ind - 1][1]:\n",
    "                        fingers.append(1)\n",
    "                    else:\n",
    "                        fingers.append(0)\n",
    "                # If other fingers detected,\n",
    "                # check if the y position of the fingertip is greater than the y position of the second joint, \n",
    "                # if true, this finger is considered to be open, \n",
    "                # otherwise, this finger is considered to be closed.\n",
    "                else:\n",
    "                    if finger_inf_list[ind][2] < finger_inf_list[ind - 2][2]:\n",
    "                        fingers.append(1)\n",
    "                    else:\n",
    "                        fingers.append(0)\n",
    "            # fingers is a list containing 5 numbers of 0 or 1\n",
    "            # 0 means one finger is closed, 1 means one finger is open\n",
    "            finger_count = fingers.count(1)\n",
    "            # Find the corresponding gesture picture and display it\n",
    "            finger_img = image_list[finger_count]\n",
    "            width, height, c = finger_img.shape\n",
    "            image[0:width, 0:height] = finger_img\n",
    "            cv2.rectangle(image, (200, 0), (300, 100), (0, 255, 0), cv2.FILLED)\n",
    "            cv2.putText(image, str(finger_count), (200, 100), cv2.FONT_HERSHEY_DUPLEX, 5, (0, 0, 255))\n",
    "\n",
    "        cv2.imshow('Finger Detection', image)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('q'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
